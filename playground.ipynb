{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d47e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install datasets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ea863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_train import create_model_and_diffusion\n",
    "from utils.step_sample import create_named_schedule_sampler\n",
    "from train_util import TrainLoop\n",
    "from utils.data import load_data_text\n",
    "\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast, BertTokenizerFast, set_seed\n",
    "import json, torch, os\n",
    "from utils import dist_util\n",
    "from functools import partial\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419eea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('vocab_list.pickle', 'rb') as handle:\n",
    "#     vocab_list = pickle.load(handle)\n",
    "# vocab_list = list(vocab_list.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cd8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_util.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb13702",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "batch_size=64\n",
    "microbatch=20\n",
    "epochs=100\n",
    "eval_interval=1000\n",
    "ema_rate='0.9999' \n",
    "schedule_sampler='uniform'\n",
    "diffusion_steps=1000\n",
    "noise_schedule='sqrt'\n",
    "vocab='custom'\n",
    "use_plm_init='no' # embedding in transformer\n",
    "vocab_size=0\n",
    "config_name='bert-base-uncased'\n",
    "cc_data_dir='data/commonsense'\n",
    "ss_data_dir='data/shakespeare'\n",
    "data_dir=ss_data_dir\n",
    "seq_len=128\n",
    "hidden_t_dim=128\n",
    "hidden_dim=64\n",
    "dropout=0.1\n",
    "seed=102\n",
    "weight_decay=0.0\n",
    "predict_xstart=True\n",
    "rescale_timesteps=True\n",
    "emb_scale_factor=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa896cd-2b1c-4ffe-8dbc-6fe4bc03ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myTokenizer():\n",
    "    \"\"\"\n",
    "    Load tokenizer from bert config or defined BPE vocab dict\n",
    "    \"\"\"\n",
    "    ################################################\n",
    "    ### You can custome your own tokenizer here. ###\n",
    "    ################################################\n",
    "    def __init__(self, vocab, config_name, custom_vocab_list=None):\n",
    "        if vocab == 'bert':\n",
    "            tokenizer = AutoTokenizer.from_pretrained(config_name)\n",
    "            self.tokenizer = tokenizer\n",
    "            self.sep_token_id = tokenizer.sep_token_id\n",
    "            self.pad_token_id = tokenizer.pad_token_id\n",
    "        elif vocab == 'shakespeare':\n",
    "            tokenizer = BertTokenizerFast('shakespeare-tokenizer-bert/vocab.txt')\n",
    "            self.tokenizer = tokenizer\n",
    "            self.sep_token_id = tokenizer.sep_token_id\n",
    "            self.pad_token_id = tokenizer.pad_token_id\n",
    "        elif vocab == 'combined':\n",
    "            tokenizer = AutoTokenizer.from_pretrained(config_name)\n",
    "            self.tokenizer = tokenizer\n",
    "            self.sep_token_id = tokenizer.sep_token_id\n",
    "            self.pad_token_id = tokenizer.pad_token_id\n",
    "            self.tokenizer.add_tokens(custom_vocab_list)\n",
    "\n",
    "        self.vocab_size = len(self.tokenizer)\n",
    "    \n",
    "    def encode_token(self, sentences):\n",
    "        if isinstance(self.tokenizer, dict):\n",
    "            input_ids = [[0] + [self.tokenizer.get(x, self.tokenizer['[UNK]']) for x in seq.split()] + [1] for seq in sentences]\n",
    "        elif isinstance(self.tokenizer, PreTrainedTokenizerFast):\n",
    "            input_ids = self.tokenizer(sentences, add_special_tokens=True)['input_ids']\n",
    "        else:\n",
    "            assert False, \"invalid type of vocab_dict\"\n",
    "        return input_ids\n",
    "        \n",
    "    def decode_token(self, seq):\n",
    "        if isinstance(self.tokenizer, dict):\n",
    "            seq = seq.squeeze(-1).tolist()\n",
    "            while len(seq)>0 and seq[-1] == self.pad_token_id:\n",
    "                seq.pop()\n",
    "            tokens = \" \".join([self.rev_tokenizer[x] for x in seq]).replace('__ ', '').replace('@@ ', '')\n",
    "        elif isinstance(self.tokenizer, PreTrainedTokenizerFast):\n",
    "            seq = seq.squeeze(-1).tolist()\n",
    "            while len(seq)>0 and seq[-1] == self.pad_token_id:\n",
    "                seq.pop()\n",
    "            tokens = self.tokenizer.decode(seq)\n",
    "        else:\n",
    "            assert False, \"invalid type of vocab_dict\"\n",
    "        return tokens\n",
    "\n",
    "\n",
    "def load_model_emb(hidden_dim, tokenizer):\n",
    "    ### random emb or pre-defined embedding like glove embedding. You can custome your own init here.\n",
    "    model = torch.nn.Embedding(tokenizer.vocab_size, hidden_dim)\n",
    "    torch.nn.init.normal_(model.weight)\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def load_tokenizer(vocab, config_name, custom_vocab_list=None):\n",
    "    tokenizer = myTokenizer(vocab, config_name, custom_vocab_list=custom_vocab_list)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06dee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load_tokenizer('bert', config_name, custom_vocab_list=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd3fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701606f-3211-4741-a7f4-bc4ee146c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode_token('find we a time for fright peace to pant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight, tokenizer = load_model_emb(hidden_dim, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## very very important to set this!!!!!\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45543e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data_text(\n",
    "        batch_size=batch_size,\n",
    "        seq_len=seq_len,\n",
    "        data_dir=data_dir,\n",
    "        loaded_vocab=tokenizer,\n",
    "        model_emb=model_weight # use model's weights as init\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2749334",
   "metadata": {},
   "source": [
    "Passed in as batch in TrainLoop - this is the batch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02903fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next(data)[0].shape # batch_size, seq_len, hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5f7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d608d",
   "metadata": {},
   "source": [
    "Passed in as cond in TrainLoop - this is a dictionary of input_ids and input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d8eb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# next(data)[1]['input_ids'].shape # batch_size, hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c90139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(data)[1]['input_mask'].shape # batch_size, hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a49540",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, diffusion = create_model_and_diffusion(\n",
    "                        hidden_t_dim,\n",
    "                        hidden_dim,\n",
    "                        vocab_size,\n",
    "                        config_name,\n",
    "                        use_plm_init,\n",
    "                        dropout,\n",
    "                        diffusion_steps,\n",
    "                        noise_schedule,\n",
    "                        predict_xstart,\n",
    "                        rescale_timesteps,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4bbaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dist_util.dev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a953179",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, hidden_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_util.dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80784a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ad85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_sampler = create_named_schedule_sampler('uniform', diffusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47493837",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe31a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TrainLoop(\n",
    "        model=model,\n",
    "        diffusion=diffusion,\n",
    "        data=data,\n",
    "        batch_size=batch_size,\n",
    "        microbatch=microbatch,\n",
    "        lr=lr,\n",
    "        ema_rate=ema_rate,\n",
    "        schedule_sampler=schedule_sampler,\n",
    "        weight_decay=weight_decay,\n",
    "        epochs=epochs,\n",
    "#         eval_data=data_valid,\n",
    "        eval_interval=eval_interval\n",
    "    ).run_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee01293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96e67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e094b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99197091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f84d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval().requires_grad_(False).to(dist_util.dev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67362550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = torch.nn.Embedding(\n",
    "        num_embeddings=tokenizer.vocab_size, \n",
    "        embedding_dim=hidden_dim, \n",
    "        _weight=model.word_embedding.weight.clone().cpu()\n",
    "    ).eval().requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807fbde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_test = load_data_text(\n",
    "        batch_size=20,\n",
    "        seq_len=seq_len,\n",
    "        deterministic=True,\n",
    "        data_dir=data_dir,\n",
    "        split=\"test\",\n",
    "        loaded_vocab=tokenizer,\n",
    "        model_emb=model_emb.cpu(),  # using the same embedding wight with tranining data\n",
    "        loop=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa23ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_data = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        batch, cond = next(data_test)\n",
    "        # print(batch.shape)\n",
    "        all_test_data.append(cond)\n",
    "        idx += 1\n",
    "\n",
    "except StopIteration:\n",
    "    print('### End of reading iteration...')\n",
    "\n",
    "model_emb.to(dist_util.dev())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_test_data) # number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_efficient_knn(model_emb, text_emb):\n",
    "    emb_norm = (model_emb**2).sum(-1).view(-1, 1) # vocab\n",
    "    text_emb_t = torch.transpose(text_emb.view(-1, text_emb.size(-1)), 0, 1) # d, bsz*seqlen\n",
    "    arr_norm = (text_emb ** 2).sum(-1).view(-1, 1) # bsz*seqlen, 1\n",
    "    # print(emb_norm.shape, arr_norm.shape)\n",
    "    dist = emb_norm + arr_norm.transpose(0, 1) - 2.0 * torch.mm(model_emb, text_emb_t) # (vocab, d) x (d, bsz*seqlen)\n",
    "    dist = torch.clamp(dist, 0.0, np.inf)\n",
    "    # print(dist.shape)\n",
    "    topk_out = torch.topk(-dist, k=1, dim=0)\n",
    "    return topk_out.values, topk_out.indices\n",
    "\n",
    "def denoised_fn_round(model, text_emb, t):\n",
    "    # print(text_emb.shape) # bsz, seqlen, dim\n",
    "    model_emb = model.weight  # input_embs\n",
    "    # print(t)\n",
    "    old_shape = text_emb.shape\n",
    "    old_device = text_emb.device\n",
    "\n",
    "    if len(text_emb.shape) > 2:\n",
    "        text_emb = text_emb.reshape(-1, text_emb.size(-1))\n",
    "    else:\n",
    "        text_emb = text_emb\n",
    "    # val, indices = get_knn(model_emb, text_emb.to(model_emb.device), dist=dist)\n",
    "    val, indices = get_efficient_knn(model_emb, text_emb.to(model_emb.device))\n",
    "    rounded_tokens = indices[0]\n",
    "    # print(rounded_tokens.shape)\n",
    "    new_embeds = model(rounded_tokens).view(old_shape).to(old_device)\n",
    "\n",
    "    return new_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4fbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1000\n",
    "clip_denoised = False\n",
    "model_kwargs = {}\n",
    "top_p = 0\n",
    "clamp_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(all_test_data)\n",
    "word_lst_recover = []\n",
    "word_lst_ref = []\n",
    "word_lst_source = []\n",
    "\n",
    "for cond in iterator:\n",
    "\n",
    "    input_ids_x = cond.pop('input_ids').to(dist_util.dev())\n",
    "    x_start = model.get_embeds(input_ids_x)\n",
    "    input_ids_mask = cond.pop('input_mask')\n",
    "    input_ids_mask_ori = input_ids_mask\n",
    "\n",
    "    noise = torch.randn_like(x_start)\n",
    "    input_ids_mask = torch.broadcast_to(input_ids_mask.unsqueeze(dim=-1), x_start.shape).to(dist_util.dev())\n",
    "    x_noised = torch.where(input_ids_mask == 0, x_start, noise)\n",
    "\n",
    "    model_kwargs = {}\n",
    "\n",
    "    if step == diffusion_steps:\n",
    "        use_ddim = False\n",
    "        step_gap = 1\n",
    "    else:\n",
    "        use_ddim = True\n",
    "        step_gap = diffusion_steps//step\n",
    "\n",
    "    sample_fn = (\n",
    "        diffusion.p_sample_loop if not use_ddim else diffusion.ddim_sample_loop\n",
    "    )\n",
    "\n",
    "    sample_shape = (x_start.shape[0], seq_len, hidden_dim)\n",
    "\n",
    "    samples = sample_fn(\n",
    "        model,\n",
    "        sample_shape,\n",
    "        noise=x_noised,\n",
    "        clip_denoised=clip_denoised,\n",
    "        denoised_fn=partial(denoised_fn_round, model_emb),\n",
    "        model_kwargs=model_kwargs,\n",
    "        top_p=top_p,\n",
    "        clamp_step=clamp_step,\n",
    "        clamp_first=True,\n",
    "        mask=input_ids_mask,\n",
    "        x_start=x_start,\n",
    "        gap=step_gap\n",
    "    )\n",
    "\n",
    "    # print(samples[0].shape) # samples for each step\n",
    "\n",
    "    sample = samples[-1]\n",
    "\n",
    "    # print('decoding for seq2seq', )\n",
    "    # print(sample.shape)\n",
    "\n",
    "    logits = model.get_logits(sample)  # bsz, seqlen, vocab\n",
    "    cands = torch.topk(logits, k=1, dim=-1)\n",
    "\n",
    "#     word_lst_recover = []\n",
    "#     word_lst_ref = []\n",
    "#     word_lst_source = []\n",
    "\n",
    "    # tokenizer = load_tokenizer(args)\n",
    "\n",
    "    for seq, input_mask in zip(cands.indices, input_ids_mask_ori):\n",
    "        len_x = seq_len - sum(input_mask).tolist()\n",
    "        tokens = tokenizer.decode_token(seq[len_x:])\n",
    "        word_lst_recover.append(tokens)\n",
    "\n",
    "    for seq, input_mask in zip(input_ids_x, input_ids_mask_ori):\n",
    "        # tokens = tokenizer.decode_token(seq)\n",
    "        len_x = seq_len - sum(input_mask).tolist()\n",
    "        word_lst_source.append(tokenizer.decode_token(seq[:len_x]))\n",
    "        word_lst_ref.append(tokenizer.decode_token(seq[len_x:]))\n",
    "    break # after 1 batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lst_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9184761",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lst_recover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fa620",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lst_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20392d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
